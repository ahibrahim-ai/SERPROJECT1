# Speech Emotion Recognition using CNN & LSTM Models

Welcome to the Speech Emotion Recognition (SER) project repo! This project explroes the use of Convolutional neural Networks (CNN) and Long Short-Term Memory (LSTM) models to enhance the accuracy and robustness of SER systems.

## Project Overview
This research, presented at the 11th IEEE International Conference on big Data (2023), explores advanced deep learning techniques to enhance the accuracy and robustness of SER systems. The approach leverages CNNs and LSTMs to effectively capture and analyse emotional nuances in speech data.

## Key Findings

Our research demonstrates that combining CNN and LSTM models significantly improves the accuracy of emotion recognition from speech data compared to traditional methods. This hybrid approach allows for better feature extraction and temporal pattern recognition, leading to more reliable emotion classification.

## Installation:
You can install the following required packages using pip
- Python 3.6 or higher
- numpy
- pandas
- matplotlib
- seaborn
- scikit-learn
- librosa
- tensorflow
- keras
- IPython

## Data Preparation

Ensure you have the RAVDESS dataset downloaded and placed in the appropriate directory. The code assumes the dataset is in the Ravdess-Emotional-Speech-audio-dataset/audio_speech_actors_01-24/ directory.

For more details, refer to the full paper [here](https://www.researchgate.net/publication/376682030_Evaluating_Speech_Emotion_Recognition_through_the_lens_of_CNN_LSTM_Deep_Learning_Models)
